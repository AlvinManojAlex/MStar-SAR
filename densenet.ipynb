{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZujQqkRCnBi",
        "outputId": "8c91fefe-da81-4842-ecbc-b51821c5c197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'MStar-SAR'...\n",
            "remote: Enumerating objects: 5787, done.\u001b[K\n",
            "remote: Counting objects: 100% (5787/5787), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5781/5781), done.\u001b[K\n",
            "remote: Total 5787 (delta 7), reused 5783 (delta 5), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (5787/5787), 32.34 MiB | 15.50 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/KaushalBarhate/MStar-SAR.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bduawxz0Cx3y",
        "outputId": "f1e21f66-15d8-4ec3-bc20-dcc4da7b4e26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/MStar-SAR\n"
          ]
        }
      ],
      "source": [
        "%cd MStar-SAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYYiumvD0c0n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import densenet121\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMtFU-n30kK9"
      },
      "outputs": [],
      "source": [
        "# Set the device to use (GPU if available, else CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LG5kBvYR0oEd"
      },
      "outputs": [],
      "source": [
        "# Set the path to your dataset\n",
        "dataset_dir = \"\"\n",
        "\n",
        "# Set the input size for resizing the images\n",
        "input_size = (224, 224)\n",
        "\n",
        "# Define the transformation to be applied to the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(input_size),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRdGiYvq0q8d"
      },
      "outputs": [],
      "source": [
        "# Load the training dataset\n",
        "train_dataset = ImageFolder(root=os.path.join(dataset_dir, 'train'), transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Load the test dataset\n",
        "test_dataset = ImageFolder(root=os.path.join(dataset_dir, 'test'), transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s747axAk000W"
      },
      "outputs": [],
      "source": [
        "# Set device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0u4WzNf04LV",
        "outputId": "7ced1632-df48-4018-a4db-db3ee1aceb58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 50.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Load the pre-trained DenseNet model\n",
        "model = densenet121(pretrained=True)\n",
        "num_classes = len(train_dataset.classes)\n",
        "model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTvFdpH1DSbR"
      },
      "outputs": [],
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYXtBBTyDXOn",
        "outputId": "51cdd3a3-1bbf-4cf9-e563-0952a47b2c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10] Train Loss: 0.6952 Train Accuracy: 0.7465 Test Accuracy: 0.6402\n",
            "Epoch [2/10] Train Loss: 0.2778 Train Accuracy: 0.9123 Test Accuracy: 0.6569\n",
            "Epoch [3/10] Train Loss: 0.1706 Train Accuracy: 0.9455 Test Accuracy: 0.9507\n",
            "Epoch [4/10] Train Loss: 0.0903 Train Accuracy: 0.9708 Test Accuracy: 0.9707\n",
            "Epoch [5/10] Train Loss: 0.0586 Train Accuracy: 0.9819 Test Accuracy: 0.9674\n",
            "Epoch [6/10] Train Loss: 0.0480 Train Accuracy: 0.9885 Test Accuracy: 0.9189\n",
            "Epoch [7/10] Train Loss: 0.0625 Train Accuracy: 0.9790 Test Accuracy: 0.8833\n",
            "Epoch [8/10] Train Loss: 0.0604 Train Accuracy: 0.9869 Test Accuracy: 0.8803\n",
            "Epoch [9/10] Train Loss: 0.0881 Train Accuracy: 0.9754 Test Accuracy: 0.9670\n",
            "Epoch [10/10] Train Loss: 0.0270 Train Accuracy: 0.9931 Test Accuracy: 0.9752\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_accuracy = train_correct / len(train_dataset)\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    # Evaluation on the test set\n",
        "    model.eval()\n",
        "    test_correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_accuracy = test_correct / len(test_dataset)\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Train Loss: {train_loss:.4f} Train Accuracy: {train_accuracy:.4f} Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment below lines to save model\n",
        "# # Path for the saved model\n",
        "# path = './models/<put_name_here>.pt'\n",
        "# Comment out below line if you have already saved model and just want to retrieve it (not saving)\n",
        "# # torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj3Bz2m0DoQh",
        "outputId": "9c142e32-736d-46ab-aec2-1efa40bd3ecb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Test Accuracy: 0.9752\n"
          ]
        }
      ],
      "source": [
        "# Calculate the final accuracy on the entire test dataset\n",
        "model.load_state_dict(torch.load(path))\n",
        "model.eval()\n",
        "test_correct = 0\n",
        "\n",
        "preds_tensor = torch.Tensor()\n",
        "labels_tensor = torch.Tensor()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        preds_tensor = torch.cat((preds_tensor, predicted))\n",
        "        labels_tensor = torch.cat((labels_tensor, labels))\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "final_test_accuracy = test_correct / len(test_dataset)\n",
        "print(f\"Final Test Accuracy: {final_test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds = preds_tensor.numpy()\n",
        "actual = labels_tensor.numpy()\n",
        "\n",
        "# Define the mapping dictionary\n",
        "class_mapping = {\n",
        "    0: '2S1',\n",
        "    1: 'BMP2',\n",
        "    2: 'BRDM2',\n",
        "    3: 'BTR60',\n",
        "    4: 'BTR70',\n",
        "    5: 'D7',\n",
        "    6: 'SLICY',\n",
        "    7: 'T62',\n",
        "    8: 'T72',\n",
        "    9: 'ZIL131',\n",
        "    10: 'ZSU_23_4'\n",
        "}\n",
        "\n",
        "y_preds = np.array([class_mapping[value] for value in preds])\n",
        "y_true = np.array([class_mapping[value] for value in actual])\n",
        "\n",
        "class_labels = ['2S1', 'BMP2', 'BRDM2', 'BTR60', 'BTR70',\n",
        "                'D7', 'SLICY', 'T62', 'T72', 'ZIL131', 'ZSU_23_4']\n",
        "\n",
        "# Create the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_preds, labels=class_labels)\n",
        "\n",
        "# Set figure size\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "\n",
        "# Create the heatmap using Seaborn\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_labels, yticklabels=class_labels, ax=ax)\n",
        "\n",
        "# Configure figure properties\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.ylabel('True Class')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the figure\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_wise_accuracies = np.diag(cm) / cm.sum(axis=1)\n",
        "\n",
        "# Display the class-wise accuracies\n",
        "for i, accuracy in enumerate(class_wise_accuracies):\n",
        "    label = class_labels[i]\n",
        "    print(f'Accuracy of class {label}: {accuracy:.2%}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
