{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaushal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: 'Could not find module 'C:\\Users\\kaushal\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import googlenet\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the device to use (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your dataset\n",
    "dataset_dir = \"\"\n",
    "\n",
    "# Set the input size for resizing the images\n",
    "input_size = (128,128)\n",
    "\n",
    "# Define the transformation to be applied to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(input_size),\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "train_dataset = ImageFolder(root=os.path.join(dataset_dir, 'train'), transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Load the test dataset\n",
    "test_dataset = ImageFolder(root=os.path.join(dataset_dir, 'test'), transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaushal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kaushal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to C:\\Users\\kaushal/.cache\\torch\\hub\\checkpoints\\googlenet-1378be20.pth\n",
      "100%|██████████| 49.7M/49.7M [00:10<00:00, 4.99MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained GoogLeNet model\n",
    "model = googlenet(pretrained=True)\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train Loss: 0.6680 Train Accuracy: 0.7553 Test Accuracy: 0.8136\n",
      "Epoch [2/10] Train Loss: 0.2114 Train Accuracy: 0.9304 Test Accuracy: 0.7947\n",
      "Epoch [3/10] Train Loss: 0.1147 Train Accuracy: 0.9639 Test Accuracy: 0.9696\n",
      "Epoch [4/10] Train Loss: 0.1244 Train Accuracy: 0.9606 Test Accuracy: 0.8310\n",
      "Epoch [5/10] Train Loss: 0.0993 Train Accuracy: 0.9718 Test Accuracy: 0.9092\n",
      "Epoch [6/10] Train Loss: 0.0789 Train Accuracy: 0.9764 Test Accuracy: 0.9378\n",
      "Epoch [7/10] Train Loss: 0.0708 Train Accuracy: 0.9823 Test Accuracy: 0.9307\n",
      "Epoch [8/10] Train Loss: 0.1295 Train Accuracy: 0.9672 Test Accuracy: 0.8118\n",
      "Epoch [9/10] Train Loss: 0.0674 Train Accuracy: 0.9800 Test Accuracy: 0.9589\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_accuracy = train_correct / len(train_dataset)\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Evaluation on the test set\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = test_correct / len(test_dataset)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Train Loss: {train_loss:.4f} Train Accuracy: {train_accuracy:.4f} Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below lines to save model\n",
    "# # Path for the saved model\n",
    "# path = './models/<put_name_here>.pt'\n",
    "# Comment out below line if you have already saved model and just want to retrieve it (not saving)\n",
    "# # torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the final accuracy on the entire test dataset\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "\n",
    "preds_tensor = torch.Tensor()\n",
    "labels_tensor = torch.Tensor()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        preds_tensor = torch.cat((preds_tensor, predicted))\n",
    "        labels_tensor = torch.cat((labels_tensor, labels))\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "final_test_accuracy = test_correct / len(test_dataset)\n",
    "print(f\"Final Test Accuracy: {final_test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds_tensor.numpy()\n",
    "actual = labels_tensor.numpy()\n",
    "\n",
    "# Define the mapping dictionary\n",
    "class_mapping = {\n",
    "    0: '2S1',\n",
    "    1: 'BMP2',\n",
    "    2: 'BRDM2',\n",
    "    3: 'BTR60',\n",
    "    4: 'BTR70',\n",
    "    5: 'D7',\n",
    "    6: 'SLICY',\n",
    "    7: 'T62',\n",
    "    8: 'T72',\n",
    "    9: 'ZIL131',\n",
    "    10: 'ZSU_23_4'\n",
    "}\n",
    "\n",
    "y_preds = np.array([class_mapping[value] for value in preds])\n",
    "y_true = np.array([class_mapping[value] for value in actual])\n",
    "\n",
    "class_labels = ['2S1', 'BMP2', 'BRDM2', 'BTR60', 'BTR70',\n",
    "                'D7', 'SLICY', 'T62', 'T72', 'ZIL131', 'ZSU_23_4']\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_preds, labels=class_labels)\n",
    "\n",
    "# Set figure size\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Create the heatmap using Seaborn\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_labels, yticklabels=class_labels, ax=ax)\n",
    "\n",
    "# Configure figure properties\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('True Class')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_wise_accuracies = np.diag(cm) / cm.sum(axis=1)\n",
    "\n",
    "# Display the class-wise accuracies\n",
    "for i, accuracy in enumerate(class_wise_accuracies):\n",
    "    label = class_labels[i]\n",
    "    print(f'Accuracy of class {label}: {accuracy:.2%}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
